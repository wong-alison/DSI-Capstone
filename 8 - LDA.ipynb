{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = joblib.load('data/txtclean2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 76640 entries, 0 to 76639\n",
      "Data columns (total 17 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   app_id               76640 non-null  int64         \n",
      " 1   dlc                  76640 non-null  int64         \n",
      " 2   recommendationid     76640 non-null  object        \n",
      " 3   review               76640 non-null  object        \n",
      " 4   voted_up             76640 non-null  object        \n",
      " 5   votes_up             76640 non-null  float64       \n",
      " 6   votes_funny          76640 non-null  float64       \n",
      " 7   weighted_vote_score  76640 non-null  float64       \n",
      " 8   review_created       76640 non-null  datetime64[ns]\n",
      " 9   review_updated       76640 non-null  datetime64[ns]\n",
      " 10  review_year          76640 non-null  int64         \n",
      " 11  steamid              76640 non-null  object        \n",
      " 12  num_games_owned      76640 non-null  int64         \n",
      " 13  num_reviews          76640 non-null  int64         \n",
      " 14  rating               76640 non-null  object        \n",
      " 15  helpful              76640 non-null  object        \n",
      " 16  review_length        76640 non-null  int64         \n",
      "dtypes: datetime64[ns](2), float64(3), int64(6), object(6)\n",
      "memory usage: 9.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['TJBs', 'YET', 'V10', 'EMPRAH', 'The', 'it', 'td', 'This', 'td', 'It'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I got this back in 2010 and it was around $2, but now its $8? For four '\n",
      " 'skins? Dont get me wrong, the skins are quite good and all, but it is a '\n",
      " 'complete ripoff at this price.']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert to list\n",
    "data = df.review.values.tolist()\n",
    "\n",
    "# Remove Emails\n",
    "data = [re.sub('\\S*@\\S*\\s?', '', sent) for sent in data]\n",
    "\n",
    "# Remove new line characters\n",
    "data = [re.sub('\\s+', ' ', sent) for sent in data]\n",
    "\n",
    "# Remove distracting single quotes\n",
    "data = [re.sub(\"\\'\", \"\", sent) for sent in data]\n",
    "\n",
    "pprint(data[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['got', 'this', 'back', 'in', 'and', 'it', 'was', 'around', 'but', 'now', 'its', 'for', 'four', 'skins', 'dont', 'get', 'me', 'wrong', 'the', 'skins', 'are', 'quite', 'good', 'and', 'all', 'but', 'it', 'is', 'complete', 'ripoff', 'at', 'this', 'price']]\n"
     ]
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data_words = list(sent_to_words(data))\n",
    "\n",
    "print(data_words[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['got', 'this', 'back', 'in', 'and', 'it', 'was', 'around', 'but', 'now', 'its', 'for', 'four', 'skins', 'dont', 'get', 'me', 'wrong', 'the', 'skins', 'are', 'quite', 'good', 'and', 'all', 'but', 'it', 'is', 'complete', 'ripoff', 'at', 'this', 'price']\n"
     ]
    }
   ],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# See trigram example\n",
    "print(trigram_mod[bigram_mod[data_words[0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['get', 'back', 'around', 'skin', 'do', 'get', 'wrong', 'skin', 'quite', 'good', 'complete', 'ripoff', 'price']]\n"
     ]
    }
   ],
   "source": [
    "#call functions in order\n",
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 2), (5, 1), (6, 1), (7, 1), (8, 1), (9, 2), (10, 1)]]\n"
     ]
    }
   ],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'around'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('around', 1),\n",
       "  ('back', 1),\n",
       "  ('complete', 1),\n",
       "  ('do', 1),\n",
       "  ('get', 2),\n",
       "  ('good', 1),\n",
       "  ('price', 1),\n",
       "  ('quite', 1),\n",
       "  ('ripoff', 1),\n",
       "  ('skin', 2),\n",
       "  ('wrong', 1)]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Human readable format of corpus (term-frequency)\n",
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=8, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/lda_model1']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#joblib.dump(lda_model, 'data/lda_model1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.050*\"game\" + 0.029*\"get\" + 0.026*\"dlc\" + 0.024*\"good\" + 0.023*\"do\" + '\n",
      "  '0.017*\"buy\" + 0.016*\"play\" + 0.016*\"really\" + 0.016*\"well\" + 0.013*\"great\"'),\n",
      " (1,\n",
      "  '0.046*\"pay\" + 0.042*\"weapon\" + 0.036*\"overall\" + 0.031*\"wait\" + '\n",
      "  '0.022*\"design\" + 0.017*\"miss\" + 0.015*\"hit\" + 0.015*\"gun\" + 0.014*\"super\" + '\n",
      "  '0.013*\"community\"'),\n",
      " (2,\n",
      "  '0.017*\"music\" + 0.016*\"new\" + 0.015*\"ship\" + 0.014*\"addition\" + '\n",
      "  '0.014*\"pass\" + 0.012*\"yet\" + 0.011*\"table\" + 0.010*\"turn\" + 0.010*\"spoiler\" '\n",
      "  '+ 0.010*\"build\"'),\n",
      " (3,\n",
      "  '0.047*\"work\" + 0.033*\"ve\" + 0.029*\"support\" + 0.021*\"steam\" + '\n",
      "  '0.019*\"scenario\" + 0.018*\"show\" + 0.018*\"keep\" + 0.017*\"never\" + '\n",
      "  '0.015*\"devs\" + 0.015*\"developer\"'),\n",
      " (4,\n",
      "  '0.041*\"make\" + 0.023*\"see\" + 0.022*\"feel\" + 0.018*\"lot\" + 0.017*\"character\" '\n",
      "  '+ 0.016*\"pretty\" + 0.015*\"re\" + 0.014*\"be\" + 0.013*\"story\" + '\n",
      "  '0.012*\"review\"'),\n",
      " (5,\n",
      "  '0.073*\"mode\" + 0.064*\"amazing\" + 0.041*\"less\" + 0.034*\"kind\" + '\n",
      "  '0.023*\"require\" + 0.020*\"understand\" + 0.020*\"dollar\" + 0.016*\"armor\" + '\n",
      "  '0.016*\"crab\" + 0.015*\"chapter\"'),\n",
      " (6,\n",
      "  '0.073*\"download\" + 0.045*\"refund\" + 0.041*\"shit\" + 0.036*\"suck\" + '\n",
      "  '0.034*\"absolute\" + 0.032*\"store\" + 0.027*\"patch\" + 0.026*\"apparently\" + '\n",
      "  '0.019*\"garbage\" + 0.016*\"sandbox\"'),\n",
      " (7,\n",
      "  '0.035*\"route\" + 0.028*\"sound\" + 0.023*\"bad\" + 0.021*\"car\" + 0.015*\"drive\" + '\n",
      "  '0.015*\"train\" + 0.013*\"track\" + 0.012*\"look\" + 0.012*\"class\" + 0.010*\"run\"')]\n"
     ]
    }
   ],
   "source": [
    "# Print the Keyword in the 8 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.2.2/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el677991404250587146726645095307\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el677991404250587146726645095307_data = {\"mdsDat\": {\"x\": [0.3363792419606228, 0.1445982265113589, 0.16020327793536707, -0.03018443257841741, -0.05053470627169503, -0.17299720456001372, -0.2013592976710571, -0.18610510532616525], \"y\": [0.11538329592084785, -0.4055554777932967, 0.1749475410506757, 0.11024296509364426, -0.0271530863396598, -0.0029627230136113837, 0.014578671281412246, 0.020518813799987542], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [47.044906846747445, 18.200598329564322, 10.292567126666125, 9.215689188058757, 8.018933553646832, 4.536811870593858, 2.0507835037612376, 0.6397095809614268]}, \"tinfo\": {\"Term\": [\"game\", \"make\", \"get\", \"work\", \"dlc\", \"good\", \"route\", \"do\", \"see\", \"new\", \"feel\", \"ve\", \"sound\", \"pay\", \"buy\", \"support\", \"weapon\", \"mode\", \"play\", \"really\", \"bad\", \"lot\", \"character\", \"amazing\", \"overall\", \"look\", \"car\", \"pretty\", \"great\", \"re\", \"game\", \"get\", \"dlc\", \"good\", \"do\", \"buy\", \"play\", \"really\", \"great\", \"time\", \"even\", \"worth\", \"pack\", \"add\", \"love\", \"fun\", \"want\", \"still\", \"say\", \"give\", \"way\", \"m\", \"think\", \"content\", \"need\", \"money\", \"recommend\", \"mission\", \"price\", \"first\", \"much\", \"well\", \"thing\", \"s\", \"go\", \"new\", \"use\", \"nice\", \"also\", \"look\", \"make\", \"see\", \"feel\", \"lot\", \"character\", \"pretty\", \"re\", \"be\", \"story\", \"review\", \"far\", \"different\", \"change\", \"fix\", \"end\", \"big\", \"skin\", \"main\", \"campaign\", \"issue\", \"release\", \"fan\", \"sure\", \"model\", \"gameplay\", \"especially\", \"maybe\", \"feature\", \"expect\", \"detail\", \"world\", \"start\", \"point\", \"move\", \"route\", \"sound\", \"bad\", \"car\", \"drive\", \"train\", \"track\", \"class\", \"locomotive\", \"card\", \"cab\", \"engine\", \"service\", \"editor\", \"ask\", \"pro\", \"tsw\", \"appear\", \"loco\", \"dtg\", \"aircraft\", \"scenery\", \"con\", \"speed\", \"sim\", \"fantastic\", \"cute\", \"station\", \"red\", \"road\", \"real\", \"run\", \"look\", \"quality\", \"include\", \"nice\", \"music\", \"ship\", \"addition\", \"pass\", \"yet\", \"table\", \"spoiler\", \"build\", \"enemy\", \"battle\", \"unit\", \"choice\", \"allow\", \"cost\", \"attack\", \"lose\", \"simply\", \"early\", \"volume\", \"value\", \"damage\", \"mechanic\", \"season\", \"upgrade\", \"force\", \"troll\", \"boat\", \"unlock\", \"slow\", \"building\", \"turn\", \"new\", \"work\", \"ve\", \"support\", \"steam\", \"scenario\", \"show\", \"keep\", \"never\", \"devs\", \"developer\", \"awesome\", \"least\", \"ever\", \"day\", \"year\", \"option\", \"plane\", \"bring\", \"product\", \"friend\", \"list\", \"learn\", \"waste\", \"image\", \"read\", \"happy\", \"bonus\", \"click\", \"module\", \"box\", \"step\", \"save\", \"system\", \"try\", \"pay\", \"weapon\", \"overall\", \"wait\", \"design\", \"miss\", \"hit\", \"gun\", \"super\", \"community\", \"outfit\", \"extremely\", \"texture\", \"simple\", \"kinda\", \"package\", \"head\", \"favourite\", \"boost\", \"useless\", \"totally\", \"terrible\", \"hell\", \"door\", \"stick\", \"rank\", \"range\", \"shoot\", \"front\", \"fuck\", \"mode\", \"amazing\", \"less\", \"kind\", \"require\", \"understand\", \"dollar\", \"armor\", \"chapter\", \"shame\", \"lol\", \"alot\", \"crew\", \"regret\", \"discount\", \"ball\", \"round\", \"tower\", \"scam\", \"movie\", \"playable\", \"clothe\", \"blast\", \"subscription\", \"wtf\", \"giant\", \"port\", \"crab\", \"pvp\", \"zen\", \"wrestler\", \"download\", \"refund\", \"shit\", \"suck\", \"absolute\", \"store\", \"patch\", \"apparently\", \"garbage\", \"sandbox\", \"child\", \"benefit\", \"purpose\", \"pointless\", \"ice\", \"ago\", \"italy\", \"gg\", \"sexy\", \"french\", \"pen\", \"cannon\", \"charity\", \"coat\", \"awsome\", \"wolf\", \"usa\", \"realm\", \"everytime\", \"refuse\"], \"Freq\": [45662.0, 14306.0, 25967.0, 7233.0, 23651.0, 21634.0, 7025.0, 21145.0, 8210.0, 14319.0, 7782.0, 5105.0, 5527.0, 4041.0, 15399.0, 4550.0, 3683.0, 2889.0, 14771.0, 14472.0, 4642.0, 6190.0, 5869.0, 2524.0, 3133.0, 9464.0, 4215.0, 5523.0, 12047.0, 5103.0, 45661.82238117817, 25966.385671932167, 23650.611243104184, 21633.62068300762, 21144.167975998735, 15398.139332281831, 14770.752703749376, 14472.1091234183, 12046.313094069115, 9985.042106116181, 9745.880807528798, 9512.28118341509, 8918.167413977473, 8527.595211214684, 8458.315559440096, 7974.153246323511, 7894.978191659958, 7188.903292310909, 7133.486838844508, 6926.305802313898, 6507.461683884018, 6349.639346279873, 6224.559560715066, 6195.246891041846, 5802.5268390654355, 5798.192265539302, 5752.683469069124, 5590.177527159689, 5571.802704603253, 5484.611773570938, 8215.04448681146, 14412.420634628328, 6386.419837938604, 7471.731468280888, 9429.198336202338, 11559.530092220899, 8204.206785329856, 6855.591574879218, 7266.895191790882, 7030.880663436401, 14305.130511161606, 8209.51158957855, 7781.213548411482, 6189.594017677671, 5868.629761367662, 5522.961510600932, 5102.713078257874, 4816.38208408843, 4446.714097898569, 4203.349770813083, 3953.9498718798636, 3410.3796014102927, 3353.594221209084, 3328.6116618978544, 3244.7734493117514, 3227.694023408074, 3197.790151667154, 2903.4311276413046, 2889.1164252232406, 2825.117784669665, 2624.6251445152784, 2523.9970238408378, 2520.0305807275777, 2391.920500471593, 2058.6799367968615, 2002.5648124075624, 1989.881447244876, 1978.2801365258554, 1957.4325651430267, 1936.108948656715, 2107.679069665034, 3595.0412897184538, 3056.2726664945935, 2010.5406930922607, 7024.503715223467, 5526.396674280114, 4641.815427501309, 4214.489082372779, 3034.554613644527, 2968.9615082555824, 2542.8745131799674, 2406.6783920583844, 1933.2047007181714, 1839.6800878782772, 1813.552784189276, 1747.9574600623587, 1602.0282901364342, 1602.8862021527739, 1523.0766256473726, 1497.7932744149628, 1376.9073697832546, 1374.174716626898, 1345.7771817541409, 1227.0575974111064, 1226.85375085981, 1157.0338571843279, 1141.728817749724, 1138.0963738977816, 1128.9766212482243, 1091.4040501714087, 1002.5569067688776, 990.7627428347628, 973.426356338194, 836.579960095605, 1877.576317356947, 2068.4859622154336, 2432.5222519712975, 1344.477093749207, 1187.4546961938968, 1164.824955577545, 2983.7939666221732, 2714.465992059324, 2527.825549258931, 2472.4870239166335, 2074.998109848665, 1943.4438943670448, 1789.2816900490607, 1774.160032526224, 1759.3524231337199, 1754.1869356468294, 1692.0067302400896, 1595.392314469087, 1379.5587223134603, 1369.7677710619482, 1345.8643543816988, 1299.472641431364, 1296.6256800727315, 1290.8348278982655, 1282.895469326618, 1252.5175622250879, 1238.2027120629127, 1207.1246117261476, 1152.333394301024, 1150.5462833010565, 1106.9766992267241, 1084.8352299640433, 1076.967223392487, 1061.78646456099, 1036.0322829502973, 1034.2734809805286, 1800.2208952974022, 2759.222403253505, 7232.255302752686, 5104.39391333688, 4549.583156171097, 3181.436512464653, 2861.7940921639715, 2760.6624736131216, 2707.0787861625186, 2579.004357951876, 2382.0374610347485, 2374.7500415118798, 2246.4364878706506, 2237.76530998259, 2157.0725774824973, 2130.7471723983044, 1907.8935071055002, 1883.0434771177358, 1749.1326597832021, 1696.966870894808, 1522.3007252033383, 1508.2088907170937, 1417.8259602711262, 1241.2452265688548, 1208.4860509386958, 1133.7342889255099, 1101.4820303979025, 1029.2400770456297, 941.1963263012199, 922.1700809342286, 873.4053471158087, 842.0647903051798, 842.3287646133427, 1134.0485371946818, 1481.798063114625, 1228.399437248018, 4040.7931945942337, 3682.5868766368744, 3132.8515859606414, 2735.755941220321, 1946.1197891576417, 1517.396697053419, 1344.8343150842566, 1310.1266161868282, 1237.2159743777272, 1126.7993683873342, 1120.5499500028297, 913.7820654571699, 874.9169438522866, 850.4959566445043, 847.1919905863177, 832.845736387438, 822.6996918269589, 816.1147424049224, 746.1200503145155, 738.586779504885, 700.6978519168978, 642.4835429007305, 631.3156649303465, 618.2344369069766, 593.6990252210074, 571.9372661462436, 565.1429052593203, 548.972949815151, 531.4848309021826, 505.4436859920391, 2889.0945817575976, 2523.806357951678, 1618.4488034173862, 1325.7268952396832, 926.8438835546596, 774.3873654368965, 772.0905321542512, 646.1930783676562, 597.6209083326354, 577.4597179446858, 562.2169028211135, 529.1195669006845, 490.04116600248557, 435.0336187957836, 433.51422228155417, 421.9697486139131, 409.1245244643864, 387.17935191700235, 368.65835675264276, 343.28985414468474, 322.95094708276287, 319.72025393931193, 277.42845632768484, 271.47457934854486, 264.52159867990855, 248.35765195234194, 223.153253598988, 627.9866977131896, 220.01711058898445, 220.8204643723548, 429.3141922546951, 899.5523336199576, 557.8477926873398, 506.2924841067464, 445.5732419266822, 422.68344943607826, 389.21932519876964, 333.33617706013763, 322.1299862080041, 234.9177090263242, 199.1946172386264, 173.58949918812507, 171.80304696395862, 156.24239030710964, 140.2617813159671, 138.9302276566269, 130.8318035918459, 110.65386617063582, 109.74535611030909, 92.64875458851172, 88.23050990202837, 76.95130659488343, 69.51304566900791, 62.93382882209511, 63.13062976618838, 60.68566346069006, 58.59514110831081, 55.02903974069979, 48.31282470658031, 46.061605428449155, 43.28291468763855], \"Total\": [45662.0, 14306.0, 25967.0, 7233.0, 23651.0, 21634.0, 7025.0, 21145.0, 8210.0, 14319.0, 7782.0, 5105.0, 5527.0, 4041.0, 15399.0, 4550.0, 3683.0, 2889.0, 14771.0, 14472.0, 4642.0, 6190.0, 5869.0, 2524.0, 3133.0, 9464.0, 4215.0, 5523.0, 12047.0, 5103.0, 45662.70223029187, 25967.265640328176, 23651.491056417184, 21634.500599768213, 21145.047939558328, 15399.01906978071, 14771.632607506926, 14472.989080682293, 12047.192971789218, 9985.922073530597, 9746.760798772202, 9513.160950731077, 8919.0470748686, 8528.475089836631, 8459.195525866837, 7975.033081964681, 7895.858085661561, 7189.783294736425, 7134.366799615237, 6927.185726414776, 6508.341697333521, 6350.519297634998, 6225.439572339876, 6196.126696536875, 5803.406842496803, 5799.072027754884, 5753.563294633489, 5591.057380562045, 5572.682438314632, 5485.491736231536, 8249.850563532995, 14851.716940924176, 6427.443209059758, 7617.83683129932, 10294.392889256775, 14319.489994739479, 9196.478390073298, 8021.165513067031, 9416.23450944531, 9464.15202648713, 14306.01197065695, 8210.393262699949, 7782.094926969687, 6190.475477607989, 5869.511015550854, 5523.843073961829, 5103.594668358643, 4817.263507124722, 4447.595356721721, 4204.231134110679, 3954.8314434342055, 3411.261131633527, 3354.475748763195, 3329.493258505788, 3245.654806663397, 3228.5756088797225, 3198.6716088773237, 2904.312298921201, 2889.9975854448626, 2825.99930173366, 2625.5066426971757, 2524.8785380148825, 2520.912134337415, 2392.802275265463, 2059.5614124775193, 2003.4462879588395, 1990.7628303008291, 1979.1615991037854, 1958.314042527164, 1936.9907676085534, 2109.4588059132143, 3891.29432710073, 3490.2374625530733, 2198.5760496175826, 7025.388645597736, 5527.281667760721, 4642.701430366808, 4215.3743469061255, 3035.4395412938243, 2969.846329446057, 2543.759800216956, 2407.5637171418653, 1934.0893795456527, 1840.5658698113, 1814.4375525565092, 1748.8424873334, 1602.9136982749346, 1603.7750424051912, 1523.9630825941092, 1498.6787419633738, 1377.7936951041045, 1375.0614202344814, 1346.6619255202997, 1227.9424490356973, 1227.7392924569194, 1157.9186688882392, 1142.6140961666617, 1138.9817980262937, 1129.8620480316442, 1092.2895858261636, 1003.4429606591456, 991.6477290521825, 974.3125915812094, 837.4668446535128, 2538.0173098396053, 3074.972329817946, 9464.15202648713, 2710.2629896873023, 3396.9320452100696, 8021.165513067031, 2984.6679955983486, 2715.339762891314, 2528.699721180937, 2473.361600174735, 2075.8725261946847, 1944.318187038099, 1790.15604292004, 1775.0339868999438, 1760.2259544971355, 1755.0606656789155, 1692.880128662456, 1596.266977936889, 1380.4326750267119, 1370.641866747581, 1346.7382718599754, 1300.3466462984102, 1297.4997703259485, 1291.708876955758, 1283.771775514825, 1253.3917742543015, 1239.0765456807014, 1207.998381610591, 1153.2076132739726, 1151.4201522939998, 1107.8507008970312, 1085.7122863132204, 1077.842153370344, 1062.660284164197, 1036.9068839511108, 1035.1473827123718, 2156.7932434017334, 14319.489994739479, 7233.145235743292, 5105.284034878921, 4550.4728942114825, 3182.3262097412367, 2862.6842932657714, 2761.552464557744, 2707.968721481446, 2579.894371949878, 2382.927243815355, 2375.6398674135075, 2247.3264387413074, 2238.6555606497122, 2157.962570609117, 2131.637093061291, 1908.7835435002605, 1883.9336928884225, 1750.0230226926044, 1697.8571824993167, 1523.1909892450196, 1509.099084101133, 1418.716042868674, 1242.1356245843876, 1209.3759411087806, 1134.6241917104112, 1102.371852639476, 1030.1298811745032, 942.0865214514254, 923.0598792413024, 874.2971531325342, 842.9548503059285, 843.219406691449, 1160.9860778104057, 1713.3898054518922, 3906.316019653237, 4041.673061721874, 3683.4664485636004, 3133.731786546128, 2736.635966838469, 1946.9998485447145, 1518.2767883149127, 1345.7141642082877, 1311.0062947545944, 1238.0956530707447, 1127.6795441254799, 1121.429515598799, 914.6621157682159, 875.797117267862, 851.3760036563408, 848.071801517926, 833.7256863273203, 823.5798077235611, 816.9948182803513, 747.0001496071625, 739.466660149303, 701.5775070057089, 643.3634763189115, 632.1956507039591, 619.1145766613519, 594.5792864453416, 572.8171208238143, 566.0223002532043, 549.8523177868346, 532.364658387541, 506.32345271568676, 2889.9923728657373, 2524.704036645978, 1619.3466515817106, 1326.624871451109, 927.7418455800288, 775.2856131025015, 772.9880682868293, 647.0905643343509, 598.5187091606422, 578.3575453959977, 563.1148700398463, 530.0175340053563, 490.9400410741516, 435.93115621320754, 434.4115240078484, 422.86717375307904, 410.0223227679316, 388.0772297563137, 369.5565913620149, 344.18813519319673, 323.8491422569155, 320.61878565130917, 278.3268150873454, 272.3731926797349, 265.4192832129587, 249.25572034472734, 224.0515725400981, 630.522579781231, 220.91449262635246, 221.72295149590275, 469.34182375214704, 900.4776331544817, 558.7732848127187, 507.21767812962605, 446.49840658582593, 423.6094465426279, 390.14488801329355, 334.26152641007167, 323.056709515783, 235.8427347097709, 200.12003392909935, 174.51481997293405, 172.72955627494775, 157.1682723487049, 141.187578888255, 139.85522379066435, 131.7573395130384, 111.58307695289308, 110.67044750344408, 93.57356092987348, 89.15648189358274, 77.87841970744152, 70.43881321891864, 63.8591690634219, 64.0603951235629, 61.61094360071679, 59.521018278843734, 55.95465597069431, 49.238450885509394, 46.986741356180616, 44.20769208804458], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -2.9894, -3.5538, -3.6472, -3.7364, -3.7593, -4.0764, -4.118, -4.1384, -4.3219, -4.5095, -4.5338, -4.558, -4.6225, -4.6673, -4.6755, -4.7344, -4.7444, -4.8381, -4.8458, -4.8753, -4.9377, -4.9622, -4.9821, -4.9868, -5.0523, -5.0531, -5.061, -5.0896, -5.0929, -5.1087, -4.7047, -4.1425, -4.9564, -4.7995, -4.5668, -4.3631, -4.706, -4.8856, -4.8273, -4.8603, -3.2004, -3.7557, -3.8093, -4.0381, -4.0913, -4.1521, -4.2312, -4.2889, -4.3688, -4.4251, -4.4863, -4.6341, -4.6509, -4.6584, -4.6839, -4.6892, -4.6985, -4.7951, -4.8, -4.8224, -4.896, -4.9351, -4.9367, -4.9889, -5.1389, -5.1665, -5.1729, -5.1787, -5.1893, -5.2003, -5.1154, -4.5814, -4.7438, -5.1626, -3.3415, -3.5814, -3.7558, -3.8524, -4.1809, -4.2027, -4.3576, -4.4127, -4.6318, -4.6813, -4.6956, -4.7325, -4.8197, -4.8191, -4.8702, -4.8869, -4.9711, -4.9731, -4.994, -5.0863, -5.0865, -5.1451, -5.1584, -5.1616, -5.1696, -5.2035, -5.2884, -5.3002, -5.3179, -5.4694, -4.661, -4.5641, -4.402, -4.9949, -5.1191, -5.1384, -4.0872, -4.1818, -4.2531, -4.2752, -4.4505, -4.516, -4.5986, -4.6071, -4.6155, -4.6184, -4.6545, -4.7133, -4.8587, -4.8658, -4.8834, -4.9185, -4.9207, -4.9251, -4.9313, -4.9553, -4.9668, -4.9922, -5.0386, -5.0402, -5.0788, -5.099, -5.1063, -5.1205, -5.145, -5.1467, -4.5925, -4.1655, -3.0628, -3.4112, -3.5263, -3.884, -3.9899, -4.0258, -4.0455, -4.0939, -4.1734, -4.1764, -4.232, -4.2358, -4.2726, -4.2848, -4.3953, -4.4084, -4.4822, -4.5125, -4.6211, -4.6304, -4.6922, -4.8252, -4.852, -4.9158, -4.9447, -5.0125, -5.1019, -5.1223, -5.1767, -5.2132, -5.2129, -4.9155, -4.6481, -4.8356, -3.0753, -3.1681, -3.3298, -3.4653, -3.8059, -4.0547, -4.1755, -4.2016, -4.2589, -4.3524, -4.3579, -4.5619, -4.6054, -4.6337, -4.6376, -4.6546, -4.6669, -4.6749, -4.7646, -4.7748, -4.8274, -4.9142, -4.9317, -4.9526, -4.9931, -5.0305, -5.0424, -5.0714, -5.1038, -5.1541, -2.6168, -2.752, -3.1963, -3.3958, -3.7537, -3.9334, -3.9364, -4.1144, -4.1925, -4.2269, -4.2536, -4.3143, -4.391, -4.5101, -4.5136, -4.5406, -4.5715, -4.6266, -4.6756, -4.7469, -4.808, -4.818, -4.9599, -4.9816, -5.0076, -5.0706, -5.1776, -4.143, -5.1918, -5.1881, -4.5233, -2.6186, -3.0964, -3.1934, -3.3212, -3.3739, -3.4564, -3.6114, -3.6456, -3.9613, -4.1262, -4.2638, -4.2742, -4.3691, -4.477, -4.4866, -4.5466, -4.7141, -4.7224, -4.8917, -4.9406, -5.0774, -5.179, -5.2784, -5.2753, -5.3148, -5.3499, -5.4127, -5.5428, -5.5905, -5.6528], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.754, 0.754, 0.754, 0.754, 0.754, 0.754, 0.754, 0.754, 0.754, 0.754, 0.754, 0.754, 0.754, 0.754, 0.754, 0.754, 0.754, 0.7539, 0.7539, 0.7539, 0.7539, 0.7539, 0.7539, 0.7539, 0.7539, 0.7539, 0.7539, 0.7539, 0.7539, 0.7539, 0.7498, 0.724, 0.7477, 0.7347, 0.6663, 0.54, 0.6399, 0.597, 0.495, 0.4569, 1.7037, 1.7036, 1.7036, 1.7036, 1.7036, 1.7036, 1.7035, 1.7035, 1.7035, 1.7035, 1.7035, 1.7035, 1.7035, 1.7035, 1.7034, 1.7034, 1.7034, 1.7034, 1.7034, 1.7034, 1.7034, 1.7034, 1.7034, 1.7033, 1.7033, 1.7033, 1.7033, 1.7033, 1.7033, 1.7033, 1.7029, 1.6245, 1.5709, 1.6143, 2.2736, 2.2736, 2.2736, 2.2735, 2.2735, 2.2735, 2.2734, 2.2734, 2.2733, 2.2733, 2.2733, 2.2732, 2.2732, 2.2732, 2.2732, 2.2732, 2.2731, 2.2731, 2.2731, 2.273, 2.273, 2.273, 2.273, 2.273, 2.273, 2.2729, 2.2729, 2.2729, 2.2728, 2.2727, 1.9723, 1.8773, 0.9152, 1.5727, 1.2227, 0.3442, 2.384, 2.3839, 2.3839, 2.3839, 2.3838, 2.3838, 2.3838, 2.3838, 2.3838, 2.3838, 2.3837, 2.3837, 2.3836, 2.3836, 2.3836, 2.3836, 2.3836, 2.3836, 2.3836, 2.3836, 2.3836, 2.3835, 2.3835, 2.3835, 2.3835, 2.3835, 2.3835, 2.3834, 2.3834, 2.3834, 2.2035, 0.7376, 2.5232, 2.5232, 2.5232, 2.5231, 2.5231, 2.523, 2.523, 2.523, 2.523, 2.523, 2.523, 2.523, 2.523, 2.5229, 2.5229, 2.5229, 2.5229, 2.5228, 2.5228, 2.5228, 2.5227, 2.5226, 2.5226, 2.5226, 2.5226, 2.5225, 2.5224, 2.5224, 2.5223, 2.5223, 2.5223, 2.4999, 2.3781, 1.3665, 3.0927, 3.0927, 3.0927, 3.0926, 3.0925, 3.0924, 3.0923, 3.0923, 3.0922, 3.0922, 3.0922, 3.092, 3.0919, 3.0919, 3.0919, 3.0919, 3.0919, 3.0919, 3.0918, 3.0918, 3.0917, 3.0916, 3.0916, 3.0915, 3.0915, 3.0914, 3.0914, 3.0913, 3.0913, 3.0912, 3.8866, 3.8866, 3.8864, 3.8863, 3.886, 3.8858, 3.8858, 3.8856, 3.8854, 3.8854, 3.8854, 3.8853, 3.8851, 3.8849, 3.8849, 3.8848, 3.8848, 3.8846, 3.8845, 3.8843, 3.8842, 3.8841, 3.8837, 3.8836, 3.8836, 3.8833, 3.8829, 3.8829, 3.8829, 3.8829, 3.7978, 5.0509, 5.0503, 5.0501, 5.0498, 5.0497, 5.0495, 5.0491, 5.049, 5.048, 5.0473, 5.0466, 5.0465, 5.046, 5.0453, 5.0453, 5.0449, 5.0435, 5.0435, 5.042, 5.0415, 5.0399, 5.0387, 5.0373, 5.0373, 5.0368, 5.0362, 5.0352, 5.0329, 5.032, 5.0308]}, \"token.table\": {\"Topic\": [8, 1, 4, 8, 3, 4, 7, 1, 2, 3, 7, 8, 3, 7, 3, 4, 5, 8, 3, 7, 4, 2, 8, 2, 7, 4, 5, 6, 5, 5, 4, 4, 1, 3, 2, 8, 3, 3, 2, 7, 2, 8, 8, 4, 3, 5, 7, 8, 6, 3, 1, 4, 4, 7, 7, 3, 4, 5, 6, 2, 5, 5, 2, 7, 1, 1, 7, 6, 8, 3, 3, 4, 3, 2, 4, 3, 2, 1, 5, 8, 2, 6, 2, 3, 2, 6, 2, 2, 1, 2, 4, 8, 5, 6, 6, 1, 1, 2, 8, 1, 8, 7, 1, 1, 2, 1, 1, 6, 5, 6, 6, 6, 8, 5, 1, 3, 2, 8, 5, 7, 6, 5, 5, 7, 5, 3, 3, 7, 1, 3, 4, 2, 1, 1, 2, 2, 2, 4, 6, 1, 7, 2, 5, 1, 2, 3, 7, 1, 2, 4, 1, 5, 1, 4, 1, 3, 5, 6, 6, 1, 6, 4, 8, 6, 8, 5, 1, 7, 1, 2, 8, 7, 2, 1, 3, 5, 8, 7, 1, 3, 6, 6, 2, 5, 2, 3, 1, 8, 1, 3, 8, 8, 7, 2, 7, 2, 3, 7, 3, 1, 3, 1, 2, 8, 2, 5, 1, 7, 5, 3, 4, 2, 3, 8, 7, 4, 8, 6, 5, 3, 6, 4, 2, 4, 3, 3, 4, 1, 2, 5, 3, 5, 5, 6, 1, 8, 2, 7, 8, 6, 5, 2, 3, 5, 4, 6, 6, 1, 2, 1, 1, 6, 7, 3, 3, 4, 1, 5, 3, 3, 4, 7, 4, 4, 4, 8, 1, 3, 6, 4, 5, 4, 6, 1, 5, 1, 6, 1, 3, 8, 5, 2, 4, 1, 1, 2, 4, 5, 6, 7, 7, 5, 4, 7], \"Freq\": [0.9985613008689914, 0.9999442936947548, 0.9997232881488157, 0.9942520127088369, 0.9993978424723705, 0.9996865656438453, 0.9980801880313906, 0.7717522320318765, 0.18659263405531953, 0.0416302291119438, 0.9997211409195855, 0.9967290278002062, 0.9992280924918245, 0.9983146650647383, 0.999368040732017, 0.9994518074703886, 0.9994097703304509, 0.9900838460667615, 0.9998489176232138, 0.9979492999057302, 0.9993956529824539, 0.9997377126821372, 0.9957763089845119, 0.9998217142946445, 0.9952328880459147, 0.9992186672531681, 0.9988466861305356, 0.998661111905147, 0.9988672580677578, 0.9994951386322996, 0.9994174833228125, 0.9988915755074748, 0.9999338224223184, 0.9997588494815417, 0.9996548144365632, 0.9937702922740217, 0.9996739680054432, 0.9996925566095833, 0.999858174928416, 0.9991333451190363, 0.9999129372873652, 0.9865458778117107, 0.9970499928142842, 0.9992062869467322, 0.9997658557745112, 0.9988517762876082, 0.9980700268387201, 0.9834469468769658, 0.9993973960696371, 0.9994625515572388, 0.9998181611525948, 0.9995317035301833, 0.0015859860250317516, 0.99599922371994, 0.9980852222359071, 0.9995585592041479, 0.9991311709640102, 0.9997011249882238, 0.9994864670660032, 0.9994885016360834, 0.9997306547081127, 0.9996108803498884, 0.9996303034025065, 0.9990526862546101, 0.999979237824118, 0.9999504404264619, 0.9987217548014433, 0.9981997247304977, 0.9994695779918391, 0.999855196821467, 0.9992324973890776, 0.9994512099681249, 0.9995167387041832, 0.9997982512921422, 0.9993035243606064, 0.9995182600265593, 0.9997772398683599, 0.9999219434242915, 0.9995539447151555, 0.9789995788662875, 0.9993289929507587, 0.9992761088966062, 0.9996520474146954, 0.998819373687255, 0.9997897651401589, 0.9987823444432056, 0.9994130852658462, 0.9998593017715716, 0.9999103569460713, 0.9998518517781864, 0.999232115937335, 0.9870286279918142, 0.9992716952036402, 0.997436609725983, 0.997386151661377, 0.9998704604790898, 0.9999846213592808, 0.9997274116352549, 0.9964267090491129, 0.9999512601617088, 0.9939419463951908, 0.9949621202554925, 0.9998288299950939, 0.9159355098871447, 0.08392918448854524, 0.999976861043503, 0.9999009751240798, 0.9992324256880988, 0.9989031662947054, 0.9992959908461528, 0.9981087331071833, 0.9994693046805316, 0.9938849349528448, 0.9994498692034142, 0.6502926672068275, 0.3494329542664121, 0.999646389957334, 0.9947745037256928, 0.9996422700625153, 0.9995289765294199, 0.9987361901244592, 0.9990857483177269, 0.9997071632361693, 0.9991683982052915, 0.9994952881006222, 0.9995084694177835, 0.9994367480855985, 0.9980201729715157, 0.7429086071654896, 0.25707532943160805, 0.9989643943772658, 0.9999231920698646, 0.9998586714465718, 0.9999182275321655, 0.9995481550239317, 0.9999292625604519, 0.9996168150775078, 0.999173524049544, 0.9991590543142468, 0.9998108800375183, 0.9996566174793211, 0.9996647130965413, 0.9985163475279697, 0.9998151380514411, 0.9146829377813839, 0.0850550518971252, 0.9965480065356412, 0.9957756127502424, 0.0041212867721860304, 0.9997761909869595, 0.9999298959201303, 0.9996533300124214, 0.8072913214260266, 0.19267445984553697, 0.8547386273018683, 0.14524073815733324, 0.9995043918520344, 0.9996169927821369, 0.9997664807979835, 0.9998826023834373, 0.9991295862185594, 0.9994494940915073, 0.9962259299668128, 0.9998334695281891, 0.9887206274762457, 0.9994154232948145, 0.9999571741645805, 0.997377969720723, 0.12406032673870417, 0.8755851235877135, 0.9915886447121888, 0.9953065603236956, 0.999847375468394, 0.9998775386320347, 0.9995471064315727, 0.9992180959226853, 0.9925667418032509, 0.9958604226663427, 0.5036411614643668, 0.4958928359033765, 0.9981938869674446, 0.9985735048864476, 0.9998834804883058, 0.9987555445685671, 0.26004550774388135, 0.7399476720348623, 0.9999316602343318, 0.9748478909625107, 0.9999020963871181, 0.9986528024039193, 0.9986161027491179, 0.9726814038235851, 0.9978639833378825, 0.9998070305026328, 0.9992003749927169, 0.9997071678336878, 0.9994425514795084, 0.9975066655858388, 0.9999446798437294, 0.3271574154488604, 0.6725263768869219, 0.9808558735860393, 0.019034274848765485, 0.9944031893903428, 0.02239475605860445, 0.9767558988637479, 0.9998084203330685, 0.9984938941016759, 0.9997609609738031, 0.9992066205400063, 0.9989528223191797, 0.9999521018436797, 0.9994299766257423, 0.9938704808903946, 0.9976527575255058, 0.9995065947511896, 0.997599298719011, 0.9984499150785338, 0.9997999442107893, 0.9992370324915807, 0.9983837885371077, 0.9996148204898542, 0.9997900350647251, 0.9991253949943363, 0.999768119694678, 0.9991380037609072, 0.9993542222620134, 0.07375437987335023, 0.9238571276818609, 0.002055871215981888, 0.9993468153728324, 0.9995832577637148, 0.9985538678524566, 0.9990257204404062, 0.9998910544721148, 0.9970654799063917, 0.9998661396386204, 0.994958414716864, 0.9988837438645369, 0.9991150497394711, 0.9998960780071706, 0.9996381728958377, 0.13482045899011036, 0.8649520355988898, 0.9993220312154221, 0.9978807060563761, 0.9990898379862808, 0.9935521469872589, 0.006223314418961847, 0.9999293909554872, 0.9999076626551051, 0.9991768450385851, 0.9972241871624621, 0.9997013081907767, 0.9997150258457261, 0.9993439456086114, 0.6853004177162392, 0.3143626869464108, 0.9994239376280173, 0.16505986426334976, 0.8345723473989595, 0.9983417555017475, 0.999480099832496, 0.9993786498149628, 0.9996351007986418, 0.9829387572109405, 0.8920806043382234, 0.10786737682880518, 0.999368923341035, 0.9996874287334983, 0.9997484890419125, 0.9993988218704095, 0.999767609997758, 0.9998913245840729, 0.998862271803159, 0.9997938495862825, 0.9998733669574261, 0.9703928547336821, 0.02955887199750808, 0.9912464824374665, 0.9998416683605864, 0.9993084454130486, 0.0004740552397595107, 0.9998779637244561, 0.02130643274033226, 0.029829005836465167, 0.004261286548066453, 0.0021306432740332264, 0.027698362562431942, 0.9140459645602541, 0.9984202986012048, 0.9995895063623487, 0.999579682189694, 0.9967393926022309], \"Term\": [\"absolute\", \"add\", \"addition\", \"ago\", \"aircraft\", \"allow\", \"alot\", \"also\", \"also\", \"also\", \"amazing\", \"apparently\", \"appear\", \"armor\", \"ask\", \"attack\", \"awesome\", \"awsome\", \"bad\", \"ball\", \"battle\", \"be\", \"benefit\", \"big\", \"blast\", \"boat\", \"bonus\", \"boost\", \"box\", \"bring\", \"build\", \"building\", \"buy\", \"cab\", \"campaign\", \"cannon\", \"car\", \"card\", \"change\", \"chapter\", \"character\", \"charity\", \"child\", \"choice\", \"class\", \"click\", \"clothe\", \"coat\", \"community\", \"con\", \"content\", \"cost\", \"crab\", \"crab\", \"crew\", \"cute\", \"damage\", \"day\", \"design\", \"detail\", \"developer\", \"devs\", \"different\", \"discount\", \"dlc\", \"do\", \"dollar\", \"door\", \"download\", \"drive\", \"dtg\", \"early\", \"editor\", \"end\", \"enemy\", \"engine\", \"especially\", \"even\", \"ever\", \"everytime\", \"expect\", \"extremely\", \"fan\", \"fantastic\", \"far\", \"favourite\", \"feature\", \"feel\", \"first\", \"fix\", \"force\", \"french\", \"friend\", \"front\", \"fuck\", \"fun\", \"game\", \"gameplay\", \"garbage\", \"get\", \"gg\", \"giant\", \"give\", \"go\", \"go\", \"good\", \"great\", \"gun\", \"happy\", \"head\", \"hell\", \"hit\", \"ice\", \"image\", \"include\", \"include\", \"issue\", \"italy\", \"keep\", \"kind\", \"kinda\", \"learn\", \"least\", \"less\", \"list\", \"loco\", \"locomotive\", \"lol\", \"look\", \"look\", \"lose\", \"lot\", \"love\", \"m\", \"main\", \"make\", \"maybe\", \"mechanic\", \"miss\", \"mission\", \"mode\", \"model\", \"module\", \"money\", \"move\", \"move\", \"movie\", \"much\", \"much\", \"music\", \"need\", \"never\", \"new\", \"new\", \"nice\", \"nice\", \"option\", \"outfit\", \"overall\", \"pack\", \"package\", \"pass\", \"patch\", \"pay\", \"pen\", \"plane\", \"play\", \"playable\", \"point\", \"point\", \"pointless\", \"port\", \"pretty\", \"price\", \"pro\", \"product\", \"purpose\", \"pvp\", \"quality\", \"quality\", \"range\", \"rank\", \"re\", \"read\", \"real\", \"real\", \"really\", \"realm\", \"recommend\", \"red\", \"refund\", \"refuse\", \"regret\", \"release\", \"require\", \"review\", \"road\", \"round\", \"route\", \"run\", \"run\", \"s\", \"s\", \"sandbox\", \"save\", \"save\", \"say\", \"scam\", \"scenario\", \"scenery\", \"season\", \"see\", \"service\", \"sexy\", \"shame\", \"ship\", \"shit\", \"shoot\", \"show\", \"sim\", \"simple\", \"simply\", \"skin\", \"slow\", \"sound\", \"speed\", \"spoiler\", \"start\", \"start\", \"start\", \"station\", \"steam\", \"step\", \"stick\", \"still\", \"store\", \"story\", \"subscription\", \"suck\", \"super\", \"support\", \"sure\", \"system\", \"system\", \"table\", \"terrible\", \"texture\", \"thing\", \"thing\", \"think\", \"time\", \"totally\", \"tower\", \"track\", \"train\", \"troll\", \"try\", \"try\", \"tsw\", \"turn\", \"turn\", \"understand\", \"unit\", \"unlock\", \"upgrade\", \"usa\", \"use\", \"use\", \"useless\", \"value\", \"ve\", \"volume\", \"wait\", \"want\", \"waste\", \"way\", \"weapon\", \"well\", \"well\", \"wolf\", \"work\", \"world\", \"world\", \"worth\", \"wrestler\", \"wrestler\", \"wrestler\", \"wrestler\", \"wrestler\", \"wrestler\", \"wtf\", \"year\", \"yet\", \"zen\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 5, 8, 3, 4, 2, 6, 7]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el677991404250587146726645095307\", ldavis_el677991404250587146726645095307_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.2.2/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el677991404250587146726645095307\", ldavis_el677991404250587146726645095307_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.2.2/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el677991404250587146726645095307\", ldavis_el677991404250587146726645095307_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "0      0.336379  0.115383       1        1  47.044907\n",
       "4      0.144598 -0.405555       2        1  18.200598\n",
       "7      0.160203  0.174948       3        1  10.292567\n",
       "2     -0.030184  0.110243       4        1   9.215689\n",
       "3     -0.050535 -0.027153       5        1   8.018934\n",
       "1     -0.172997 -0.002963       6        1   4.536812\n",
       "5     -0.201359  0.014579       7        1   2.050784\n",
       "6     -0.186105  0.020519       8        1   0.639710, topic_info=           Term          Freq         Total Category  logprob  loglift\n",
       "29         game  45662.000000  45662.000000  Default  30.0000  30.0000\n",
       "176        make  14306.000000  14306.000000  Default  29.0000  29.0000\n",
       "4           get  25967.000000  25967.000000  Default  28.0000  28.0000\n",
       "519        work   7233.000000   7233.000000  Default  27.0000  27.0000\n",
       "78          dlc  23651.000000  23651.000000  Default  26.0000  26.0000\n",
       "...         ...           ...           ...      ...      ...      ...\n",
       "5678       wolf     58.595141     59.521018   Topic8  -5.3499   5.0362\n",
       "965         usa     55.029040     55.954656   Topic8  -5.4127   5.0352\n",
       "2570      realm     48.312825     49.238451   Topic8  -5.5428   5.0329\n",
       "247   everytime     46.061605     46.986741   Topic8  -5.5905   5.0320\n",
       "7343     refuse     43.282915     44.207692   Topic8  -5.6528   5.0308\n",
       "\n",
       "[297 rows x 6 columns], token_table=       Topic      Freq      Term\n",
       "term                            \n",
       "839        8  0.998561  absolute\n",
       "13         1  0.999944       add\n",
       "968        4  0.999723  addition\n",
       "245        8  0.994252       ago\n",
       "8218       3  0.999398  aircraft\n",
       "...      ...       ...       ...\n",
       "24609      7  0.914046  wrestler\n",
       "1336       7  0.998420       wtf\n",
       "695        5  0.999590      year\n",
       "617        4  0.999580       yet\n",
       "10895      7  0.996739       zen\n",
       "\n",
       "[294 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 5, 8, 3, 4, 2, 6, 7])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'int' and 'tuple'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-20606fa66840>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mdf_topic_sents_keywords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat_topics_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mldamodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlda_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-20606fa66840>\u001b[0m in \u001b[0;36mformat_topics_sentences\u001b[0;34m(ldamodel, corpus, texts)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Get main topic in each document\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mldamodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;31m# Get the Dominant topic, Perc Contribution and Keywords for each document\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtopic_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprop_topic\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'int' and 'tuple'"
     ]
    }
   ],
   "source": [
    "def format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=data):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=data)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "\n",
    "# Show\n",
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_ready' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-7f832364a1cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m#Join topics dataframe to original data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mnew_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_ready\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopics_comb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data_ready' is not defined"
     ]
    }
   ],
   "source": [
    "topics_df1 = pd.DataFrame()\n",
    "topics_df2 = pd.DataFrame()\n",
    "topics_df3 = pd.DataFrame()\n",
    "\n",
    "for i, row_list in enumerate(lda_model[corpus]):\n",
    "    row = row_list[0] if lda_model.per_word_topics else row_list            \n",
    "    row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "    for j, (topic_num, prop_topic) in enumerate(row):\n",
    "        if len(row) >= 3:        \n",
    "            if j ==0:\n",
    "                topics_df1 = topics_df1.append(pd.Series([int(topic_num), prop_topic]), ignore_index=True)\n",
    "            elif j ==1:\n",
    "                topics_df2 = topics_df2.append(pd.Series([int(topic_num), prop_topic]), ignore_index=True)\n",
    "            elif j ==2:\n",
    "                topics_df3 = topics_df3.append(pd.Series([int(topic_num), prop_topic]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "        elif len(row) == 2:\n",
    "            if j ==0:\n",
    "                topics_df1 = topics_df1.append(pd.Series([int(topic_num), prop_topic]), ignore_index=True)\n",
    "            elif j ==1:\n",
    "                topics_df2 = topics_df2.append(pd.Series([int(topic_num), prop_topic]), ignore_index=True)\n",
    "                topics_df3 = topics_df3.append(pd.Series(['-', '-']), ignore_index=True)\n",
    "        elif len(row) == 1:\n",
    "                topics_df1 = topics_df1.append(pd.Series([int(topic_num), prop_topic]), ignore_index=True)\n",
    "                topics_df2 = topics_df2.append(pd.Series(['-', '-']), ignore_index=True)  \n",
    "                topics_df3 = topics_df3.append(pd.Series(['-', '-']), ignore_index=True)        \n",
    "                \n",
    "            \n",
    "topics_df1.rename(columns={0:'1st Topic', 1:'1st Topic Contribution'}, inplace=True)\n",
    "topics_df2.rename(columns={0:'2nd Topic', 1:'2nd Topic Contribution'}, inplace=True)\n",
    "topics_df3.rename(columns={0:'3rd Topic', 1:'3rd Topic Contribution'}, inplace=True)\n",
    "\n",
    "topics_comb = pd.concat([topics_df1, topics_df2, topics_df3],  axis=1, sort=False)\n",
    "\n",
    "#Join topics dataframe to original data\n",
    "#new_df = pd.concat([data_ready, topics_comb], axis=1, sort=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1st Topic</th>\n",
       "      <th>1st Topic Contribution</th>\n",
       "      <th>2nd Topic</th>\n",
       "      <th>2nd Topic Contribution</th>\n",
       "      <th>3rd Topic</th>\n",
       "      <th>3rd Topic Contribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.562136</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.190122</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.059228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.520859</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.165025</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.081263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.503444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.386642</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.032853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.447371</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.230889</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.137509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.513402</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.206071</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.076301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76635</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.482119</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.205010</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.090810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76636</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.486952</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.154192</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.108610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76637</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.503398</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.193177</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.078505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76638</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.519616</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.154194</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.108297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76639</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.497688</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.140435</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.100528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76640 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1st Topic  1st Topic Contribution  2nd Topic  2nd Topic Contribution  \\\n",
       "0            0.0                0.562136        4.0                0.190122   \n",
       "1            0.0                0.520859        4.0                0.165025   \n",
       "2            4.0                0.503444        0.0                0.386642   \n",
       "3            0.0                0.447371        7.0                0.230889   \n",
       "4            0.0                0.513402        4.0                0.206071   \n",
       "...          ...                     ...        ...                     ...   \n",
       "76635        0.0                0.482119        4.0                0.205010   \n",
       "76636        0.0                0.486952        4.0                0.154192   \n",
       "76637        0.0                0.503398        4.0                0.193177   \n",
       "76638        0.0                0.519616        4.0                0.154194   \n",
       "76639        0.0                0.497688        4.0                0.140435   \n",
       "\n",
       "       3rd Topic  3rd Topic Contribution  \n",
       "0            7.0                0.059228  \n",
       "1            7.0                0.081263  \n",
       "2            1.0                0.032853  \n",
       "3            4.0                0.137509  \n",
       "4            7.0                0.076301  \n",
       "...          ...                     ...  \n",
       "76635        7.0                0.090810  \n",
       "76636        7.0                0.108610  \n",
       "76637        7.0                0.078505  \n",
       "76638        3.0                0.108297  \n",
       "76639        2.0                0.100528  \n",
       "\n",
       "[76640 rows x 6 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join topics dataframe to original data\n",
    "new_df = pd.concat([data, topics_comb], axis=1, sort=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4977</td>\n",
       "      <td>game, get, dlc, good, do, buy, play, really, w...</td>\n",
       "      <td>I got this back in 2010 and it was around $2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4977</td>\n",
       "      <td>game, get, dlc, good, do, buy, play, really, w...</td>\n",
       "      <td>DJ Scully nuff said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4977</td>\n",
       "      <td>game, get, dlc, good, do, buy, play, really, w...</td>\n",
       "      <td>These Killing Floor characters really adds to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4977</td>\n",
       "      <td>game, get, dlc, good, do, buy, play, really, w...</td>\n",
       "      <td>Guy in a HaZmat suit... cool Some guy with som...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4977</td>\n",
       "      <td>game, get, dlc, good, do, buy, play, really, w...</td>\n",
       "      <td>This DLC has the best looking character models...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4977</td>\n",
       "      <td>game, get, dlc, good, do, buy, play, really, w...</td>\n",
       "      <td>As far as [url=]Killing Floor[/url]s DLC chara...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4977</td>\n",
       "      <td>game, get, dlc, good, do, buy, play, really, w...</td>\n",
       "      <td>DOSH! Spend it while you can! Twelve cents per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4977</td>\n",
       "      <td>game, get, dlc, good, do, buy, play, really, w...</td>\n",
       "      <td>I bought this pack first because of DJ Scully,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4977</td>\n",
       "      <td>game, get, dlc, good, do, buy, play, really, w...</td>\n",
       "      <td>my balls itch holy shit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4977</td>\n",
       "      <td>game, get, dlc, good, do, buy, play, really, w...</td>\n",
       "      <td>Remember when these character DLCs only cost t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0            0             0.0              0.4977   \n",
       "1            1             0.0              0.4977   \n",
       "2            2             0.0              0.4977   \n",
       "3            3             0.0              0.4977   \n",
       "4            4             0.0              0.4977   \n",
       "5            5             0.0              0.4977   \n",
       "6            6             0.0              0.4977   \n",
       "7            7             0.0              0.4977   \n",
       "8            8             0.0              0.4977   \n",
       "9            9             0.0              0.4977   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  game, get, dlc, good, do, buy, play, really, w...   \n",
       "1  game, get, dlc, good, do, buy, play, really, w...   \n",
       "2  game, get, dlc, good, do, buy, play, really, w...   \n",
       "3  game, get, dlc, good, do, buy, play, really, w...   \n",
       "4  game, get, dlc, good, do, buy, play, really, w...   \n",
       "5  game, get, dlc, good, do, buy, play, really, w...   \n",
       "6  game, get, dlc, good, do, buy, play, really, w...   \n",
       "7  game, get, dlc, good, do, buy, play, really, w...   \n",
       "8  game, get, dlc, good, do, buy, play, really, w...   \n",
       "9  game, get, dlc, good, do, buy, play, really, w...   \n",
       "\n",
       "                                                Text  \n",
       "0  I got this back in 2010 and it was around $2, ...  \n",
       "1                               DJ Scully nuff said.  \n",
       "2  These Killing Floor characters really adds to ...  \n",
       "3  Guy in a HaZmat suit... cool Some guy with som...  \n",
       "4  This DLC has the best looking character models...  \n",
       "5  As far as [url=]Killing Floor[/url]s DLC chara...  \n",
       "6  DOSH! Spend it while you can! Twelve cents per...  \n",
       "7  I bought this pack first because of DJ Scully,...  \n",
       "8                            my balls itch holy shit  \n",
       "9  Remember when these character DLCs only cost t...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=data):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = row_list[0] if lda_model.per_word_topics else row_list  \n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=data)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "\n",
    "# Show\n",
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
